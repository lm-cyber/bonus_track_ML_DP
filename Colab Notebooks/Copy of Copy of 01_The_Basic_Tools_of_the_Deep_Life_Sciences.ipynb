{"cells":[{"cell_type":"markdown","metadata":{"id":"socSJe925zFv"},"source":["#  Molecular Fingerprints\n","\n","Molecules can be represented in many ways.  This tutorial introduces a type of representation called a \"molecular fingerprint\".  It is a very simple representation that often works well for small drug-like molecules.\n","\n","## Colab\n","\n","This tutorial and the rest in this sequence can be done in Google colab. If you'd like to open this notebook in colab, you can use the following link.\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deepchem/deepchem/blob/master/examples/tutorials/Molecular_Fingerprints.ipynb)\n","\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CMWAv-Z46nCc","outputId":"468fde17-8989-42ec-e045-ef415ce56ce5","executionInfo":{"status":"ok","timestamp":1682432467799,"user_tz":-180,"elapsed":18908,"user":{"displayName":"Ппп Ппп","userId":"14934001101230122694"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting deepchem\n","  Downloading deepchem-2.7.2.dev20230419161626-py3-none-any.whl (773 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m773.0/773.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from deepchem) (1.10.1)\n","Collecting rdkit\n","  Downloading rdkit-2023.3.1b1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from deepchem) (1.5.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from deepchem) (1.2.0)\n","Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.9/dist-packages (from deepchem) (1.22.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from deepchem) (1.2.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->deepchem) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->deepchem) (2.8.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from rdkit->deepchem) (8.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->deepchem) (3.1.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->deepchem) (1.16.0)\n","Installing collected packages: rdkit, deepchem\n","Successfully installed deepchem-2.7.2.dev20230419161626 rdkit-2023.3.1b1\n"]}],"source":["!pip install --pre deepchem"]},{"cell_type":"markdown","metadata":{"id":"Jk47QTZ95zF-"},"source":["We can now import the `deepchem` package to play with."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":159},"id":"PDiY03h35zF_","outputId":"3c9d4397-65ba-4801-c0b3-dfa5a088d858","executionInfo":{"status":"ok","timestamp":1682432505782,"user_tz":-180,"elapsed":37995,"user":{"displayName":"Ппп Ппп","userId":"14934001101230122694"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for AvgIpc. Feature removed!\n","WARNING:deepchem.models.torch_models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n","WARNING:deepchem.models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/usr/local/lib/python3.9/dist-packages/deepchem/models/torch_models/__init__.py)\n","WARNING:deepchem.models:Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'pytorch_lightning'\n","WARNING:deepchem.models:Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n"]},{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["'2.7.2.dev'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}],"source":["import deepchem as dc\n","import os\n","import pandas as pd\n","from deepchem.molnet.load_function.molnet_loader import TransformerGenerator, _MolnetLoader\n","from google.colab import drive\n","import traceback\n","\n","from deepchem.data import Dataset\n","from typing import List, Optional, Tuple, Union\n","\n","drive.mount('/content/drive')\n","dc.__version__"]},{"cell_type":"markdown","metadata":{"id":"B0u7qIZd5zGG"},"source":["# What is a Fingerprint?\n","\n","Deep learning models almost always take arrays of numbers as their inputs.  If we want to process molecules with them, we somehow need to represent each molecule as one or more arrays of numbers.\n","\n","Many (but not all) types of models require their inputs to have a fixed size.  This can be a challenge for molecules, since different molecules have different numbers of atoms.  If we want to use these types of models, we somehow need to represent variable sized molecules with fixed sized arrays.\n","\n","Fingerprints are designed to address these problems.  A fingerprint is a fixed length array, where different elements indicate the presence of different features in the molecule.  If two molecules have similar fingerprints, that indicates they contain many of the same features, and therefore will likely have similar chemistry.\n","\n","DeepChem supports a particular type of fingerprint called an \"Extended Connectivity Fingerprint\", or \"ECFP\" for short.  They also are sometimes called \"circular fingerprints\".  The ECFP algorithm begins by classifying atoms based only on their direct properties and bonds.  Each unique pattern is a feature.  For example, \"carbon atom bonded to two hydrogens and two heavy atoms\" would be a feature, and a particular element of the fingerprint is set to 1 for any molecule that contains that feature.  It then iteratively identifies new features by looking at larger circular neighborhoods.  One specific feature bonded to two other specific features becomes a higher level feature, and the corresponding element is set for any molecule that contains it.  This continues for a fixed number of iterations, most often two.\n","\n","Let's take a look at a dataset that has been featurized with ECFP."]},{"cell_type":"code","source":["\"\"\"\n","Delaney dataset loader.\n","\"\"\"\n","\n","DELANEY_URL = \"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/delaney-processed.csv\"\n","DELANEY_TASKS = ['measured log solubility in mols per litre']\n","\n","\n","class My(_MolnetLoader):\n","\n","    def create_dataset(self) -> Dataset:\n","        dataset_file = os.path.join(self.data_dir, \"delaney-processed.csv\")\n","        # if not os.path.exists(dataset_file):\n","        #     dc.utils.data_utils.download_url(url=DELANEY_URL,\n","        #                                      dest_dir=self.data_dir)\n","        loader = dc.data.CSVLoader(tasks=self.tasks,\n","                                   feature_field=\"smiles\",\n","                                   featurizer=self.featurizer)\n","        return loader.create_dataset(dataset_file, shard_size=8192)\n","\n","\n","def load_delaney(\n","    featurizer: Union[dc.feat.Featurizer, str] = 'ECFP',\n","    splitter: Union[dc.splits.Splitter, str, None] = 'scaffold',\n","    transformers: List[Union[TransformerGenerator, str]] = ['normalization'],\n","    reload: bool = True,\n","    data_dir: Optional[str] = \"/content/drive/MyDrive\",\n","    save_dir: Optional[str] = \"/content/drive/MyDrive\",\n","    **kwargs\n",") -> Tuple[List[str], Tuple[Dataset, ...], List[dc.trans.Transformer]]:\n","    \"\"\"Load Delaney dataset\n","    The Delaney (ESOL) dataset a regression dataset containing structures and\n","    water solubility data for 1128 compounds. The dataset is widely used to\n","    validate machine learning models on estimating solubility directly from\n","    molecular structures (as encoded in SMILES strings).\n","    Scaffold splitting is recommended for this dataset.\n","    The raw data csv file contains columns below:\n","    - \"Compound ID\" - Name of the compound\n","    - \"smiles\" - SMILES representation of the molecular structure\n","    - \"measured log solubility in mols per litre\" - Log-scale water solubility\n","        of the compound, used as label\n","    Parameters\n","    ----------\n","    featurizer: Featurizer or str\n","        the featurizer to use for processing the data.  Alternatively you can pass\n","        one of the names from dc.molnet.featurizers as a shortcut.\n","    splitter: Splitter or str\n","        the splitter to use for splitting the data into training, validation, and\n","        test sets.  Alternatively you can pass one of the names from\n","        dc.molnet.splitters as a shortcut.  If this is None, all the data\n","        will be included in a single dataset.\n","    transformers: list of TransformerGenerators or strings\n","        the Transformers to apply to the data.  Each one is specified by a\n","        TransformerGenerator or, as a shortcut, one of the names from\n","        dc.molnet.transformers.\n","    reload: bool\n","        if True, the first call for a particular featurizer and splitter will cache\n","        the datasets to disk, and subsequent calls will reload the cached datasets.\n","    data_dir: str\n","        a directory to save the raw data in\n","    save_dir: str\n","        a directory to save the dataset in\n","    References\n","    ----------\n","    .. [1] Delaney, John S. \"ESOL: estimating aqueous solubility directly from\n","        molecular structure.\" Journal of chemical information and computer\n","        sciences 44.3 (2004): 1000-1005.\n","    \"\"\"\n","    loader = My(featurizer, splitter, transformers, DELANEY_TASKS,\n","                            data_dir, save_dir, **kwargs)\n","    return loader.load_dataset('delaney', reload)"],"metadata":{"id":"p7-OE0gBVnnk","executionInfo":{"status":"ok","timestamp":1682432505785,"user_tz":-180,"elapsed":39,"user":{"displayName":"Ппп Ппп","userId":"14934001101230122694"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","Tox21 dataset loader.\n","\"\"\"\n","# import os\n","# import deepchem as dc\n","# from deepchem.molnet.load_function.molnet_loader import TransformerGenerator, _MolnetLoader\n","# from deepchem.data import Dataset\n","# from typing import List, Optional, Tuple, Union\n","\n","# TOX21_URL = \"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/tox21.csv.gz\"\n","TOX21_TASKS = [\n","    'NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD',\n","    'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53'\n","]\n","DELANEY_TASKS = ['mouse_intraperitoneal_LD50',\n","       'mammal (species unspecified)_intraperitoneal_LD50',\n","       'guinea pig_intraperitoneal_LD50', 'rat_intraperitoneal_LD50',\n","       'rabbit_intraperitoneal_LD50', 'mouse_intraperitoneal_LDLo',\n","       'rat_intraperitoneal_LDLo', 'mouse_intravenous_LD50',\n","       'guinea pig_intravenous_LD50', 'rat_intravenous_LD50',\n","       'rabbit_intravenous_LD50', 'dog_intravenous_LD50',\n","       'cat_intravenous_LD50', 'mouse_intravenous_LDLo',\n","       'guinea pig_intravenous_LDLo', 'rat_intravenous_LDLo',\n","       'rabbit_intravenous_LDLo', 'dog_intravenous_LDLo',\n","       'cat_intravenous_LDLo', 'mouse_oral_LD50',\n","       'mammal (species unspecified)_oral_LD50', 'guinea pig_oral_LD50',\n","       'rat_oral_LD50', 'rabbit_oral_LD50', 'dog_oral_LD50', 'cat_oral_LD50',\n","       'bird - wild_oral_LD50', 'quail_oral_LD50', 'duck_oral_LD50',\n","       'chicken_oral_LD50', 'mouse_oral_LDLo', 'rat_oral_LDLo',\n","       'rabbit_oral_LDLo', 'dog_oral_LDLo', 'cat_oral_LDLo', 'man_oral_TDLo',\n","       'women_oral_TDLo', 'human_oral_TDLo', 'mouse_unreported_LD50',\n","       'mammal (species unspecified)_unreported_LD50', 'rat_unreported_LD50',\n","       'mouse_skin_LD50', 'guinea pig_skin_LD50', 'rat_skin_LD50',\n","       'rabbit_skin_LD50', 'rabbit_skin_LDLo', 'mouse_subcutaneous_LD50',\n","       'mammal (species unspecified)_subcutaneous_LD50',\n","       'guinea pig_subcutaneous_LD50', 'rat_subcutaneous_LD50',\n","       'rabbit_subcutaneous_LD50', 'mouse_subcutaneous_LDLo',\n","       'guinea pig_subcutaneous_LDLo', 'rat_subcutaneous_LDLo',\n","       'rabbit_subcutaneous_LDLo', 'frog_subcutaneous_LDLo',\n","       'mouse_intramuscular_LD50', 'rat_intramuscular_LD50',\n","       'mouse_parenteral_LD50']\n","\n","\n","class MyLoader(_MolnetLoader):\n","\n","    def create_dataset(self) -> Dataset:\n","        # self.transformers = ['normalization']\n","        dataset_file = os.path.join(self.data_dir, \"dataset.csv\")\n","        # dataset_file = os.path.join(self.data_dir, \"3.csv\")\n","        # dataset_file = os.path.join(self.data_dir, \"dataset.csv\")\n","        # if not os.path.exists(dataset_file):\n","        #     dc.utils.data_utils.download_url(url=TOX21_URL,\n","        #                                      dest_dir=self.data_dir)\n","        loader = dc.data.CSVLoader(tasks=self.tasks,\n","                                   feature_field=\"SMILES\",\n","                                   featurizer=self.featurizer)\n","        return loader.create_dataset(dataset_file, shard_size=8192)\n","\n","\n","def load_tox21(\n","    featurizer: Union[dc.feat.Featurizer, str] = 'ECFP',\n","    splitter: Union[dc.splits.Splitter, str, None] = 'scaffold',\n","    transformers: List[Union[TransformerGenerator, str]] = ['balancing'],\n","    reload: bool = False,\n","    data_dir: Optional[str] = \"/content/drive/MyDrive\",\n","    save_dir: Optional[str] = \"/content/drive/MyDrive\",\n","    **kwargs\n",") -> Tuple[List[str], Tuple[Dataset, ...], List[dc.trans.Transformer]]:\n","    \"\"\"Load Tox21 dataset\n","    The \"Toxicology in the 21st Century\" (Tox21) initiative created a public\n","    database measuring toxicity of compounds, which has been used in the 2014\n","    Tox21 Data Challenge. This dataset contains qualitative toxicity measurements\n","    for 8k compounds on 12 different targets, including nuclear receptors and\n","    stress response pathways.\n","    Random splitting is recommended for this dataset.\n","    The raw data csv file contains columns below:\n","    - \"smiles\" - SMILES representation of the molecular structure\n","    - \"NR-XXX\" - Nuclear receptor signaling bioassays results\n","    - \"SR-XXX\" - Stress response bioassays results\n","    please refer to https://tripod.nih.gov/tox21/challenge/data.jsp for details.\n","    Parameters\n","    ----------\n","    featurizer: Featurizer or str\n","        the featurizer to use for processing the data.  Alternatively you can pass\n","        one of the names from dc.molnet.featurizers as a shortcut.\n","    splitter: Splitter or str\n","        the splitter to use for splitting the data into training, validation, and\n","        test sets.  Alternatively you can pass one of the names from\n","        dc.molnet.splitters as a shortcut.  If this is None, all the data\n","        will be included in a single dataset.\n","    transformers: list of TransformerGenerators or strings\n","        the Transformers to apply to the data.  Each one is specified by a\n","        TransformerGenerator or, as a shortcut, one of the names from\n","        dc.molnet.transformers.\n","    reload: bool\n","        if True, the first call for a particular featurizer and splitter will cache\n","        the datasets to disk, and subsequent calls will reload the cached datasets.\n","    data_dir: str\n","        a directory to save the raw data in\n","    save_dir: str\n","        a directory to save the dataset in\n","    References\n","    ----------\n","    .. [1] Tox21 Challenge. https://tripod.nih.gov/tox21/challenge/\n","    \"\"\"\n","    loader = MyLoader(featurizer, splitter, transformers, DELANEY_TASKS,\n","                          data_dir, save_dir, **kwargs)\n","    return loader.load_dataset('tox21', reload)"],"metadata":{"id":"C-uCNVi-T1ZS","executionInfo":{"status":"ok","timestamp":1682433074216,"user_tz":-180,"elapsed":1336,"user":{"displayName":"Ппп Ппп","userId":"14934001101230122694"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# featurizer_name = str(self.featurizer)\n","# splitter_name = 'None' if self.splitter is None else str(self.splitter)\n","# save_folder = os.path.join(self.save_dir, name + \"-featurized\", featurizer_name, splitter_name)\n","# if len(self.transformers) > 0:\n","#   transformer_name = '_'.join(\n","#   t.get_directory_name() for t in self.transformers)\n","#   save_folder = os.path.join(save_folder, transformer_name)\n","\n","#         # Create the dataset\n","\n","#         logger.info(\"About to featurize %s dataset.\" % name)\n","#         dataset = self.create_dataset()\n","\n","#         # Split and transform the dataset.\n","\n","#         if self.splitter is None:\n","#             transformer_dataset: Dataset = dataset\n","#         else:\n","#             logger.info(\"About to split dataset with {} splitter.\".format(\n","#                 self.splitter.__class__.__name__))\n","#             train, valid, test = self.splitter.train_valid_test_split(dataset)\n","#             transformer_dataset = train\n","#         transformers = [\n","#             t.create_transformer(transformer_dataset) for t in self.transformers\n","#         ]\n","#         logger.info(\"About to transform data.\")\n","#         if self.splitter is None:\n","#             for transformer in transformers:\n","#                 dataset = transformer.transform(dataset)\n","#             if reload and isinstance(dataset, DiskDataset):\n","#                 dataset.move(save_folder)\n","#                 dc.utils.data_utils.save_transformers(save_folder, transformers)\n","#             return self.tasks, (dataset,), transformers\n","\n","#         for transformer in transformers:\n","#             train = transformer.transform(train)\n","#             valid = transformer.transform(valid)\n","#             test = transformer.transform(test)\n","#         if reload and isinstance(train, DiskDataset) and isinstance(\n","#                 valid, DiskDataset) and isinstance(test, DiskDataset):\n","#             dc.utils.data_utils.save_dataset_to_disk(save_folder, train, valid,\n","#                                                      test, transformers)\n","#         return self.tasks, (train, valid, test), transformers"],"metadata":{"id":"aFhSPBEITKvD","executionInfo":{"status":"ok","timestamp":1682433074762,"user_tz":-180,"elapsed":6,"user":{"displayName":"Ппп Ппп","userId":"14934001101230122694"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# TOX21_TASKS=['measured log solubility in mols per litre']\n","# class MyDataLoader(_MolnetLoader):\n","\n","#     def create_dataset(self):\n","#         dataset_file = \"/content/drive/MyDrive/delaney-processed.csv\"\n","#         # if not os.path.exists(dataset_file):\n","#         #     dc.utils.data_utils.download_url(url=TOX21_URL,\n","#         #                                      dest_dir=self.data_dir)\n","#         loader = dc.data.CSVLoader(tasks=self.tasks,\n","#                                    feature_field=\"smiles\",\n","#                                    featurizer=self.featurizer)\n","#         return loader.create_dataset(dataset_file, shard_size=8192)\n","\n","# loader = MyDataLoader('ECFP', 'scaffold', ['balancing'], TOX21_TASKS, \"\", \"save\")"],"metadata":{"id":"ckMR01jwIIcF","executionInfo":{"status":"ok","timestamp":1682433075194,"user_tz":-180,"elapsed":16,"user":{"displayName":"Ппп Ппп","userId":"14934001101230122694"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","execution_count":24,"metadata":{"id":"saTaOpXY5zGI","executionInfo":{"status":"ok","timestamp":1682436734985,"user_tz":-180,"elapsed":3659803,"user":{"displayName":"Ппп Ппп","userId":"14934001101230122694"}}},"outputs":[],"source":["tasks, datasets, transformers = load_tox21(featurizer='ECFP')\n","# print(pd.read_csv(\"/content/drive/MyDrive/delaney-processed.csv\").head())\n","# tasks, datasets, transformers = loader.load_dataset('delaney', False)\n","# train_dataset, valid_dataset, test_dataset = datasets\n","# print(train_dataset)\n","# train_dataset.to_dataframe().head(10)\n"]},{"cell_type":"markdown","metadata":{"id":"F922OPtL5zGM"},"source":["The feature array `X` has shape (6264, 1024).  That means there are 6264 samples in the training set.  Each one is represented by a fingerprint of length 1024.  Also notice that the label array `y` has shape (6264, 12): this is a multitask dataset.  Tox21 contains information about the toxicity of molecules.  12 different assays were used to look for signs of toxicity.  The dataset records the results of all 12 assays, each as a different task.\n","\n","Let's also take a look at the weights array."]},{"cell_type":"code","source":["!head -n 4000 /usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py | tail -n 500"],"metadata":{"id":"ALt8LxV7xb5t","executionInfo":{"status":"ok","timestamp":1682432411361,"user_tz":-180,"elapsed":513,"user":{"displayName":"","userId":""}},"outputId":"1cf77583-7b7b-4437-d722-37f1a1ada476","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["        elif not self._should_compare(other):\n","            # We can infer that the intersection is empty.\n","            if isinstance(self, ABCMultiIndex):\n","                return self[:0].rename(result_name)\n","            return Index([], name=result_name)\n","\n","        elif not is_dtype_equal(self.dtype, other.dtype):\n","            dtype = self._find_common_type_compat(other)\n","            this = self.astype(dtype, copy=False)\n","            other = other.astype(dtype, copy=False)\n","            return this.intersection(other, sort=sort)\n","\n","        result = self._intersection(other, sort=sort)\n","        return self._wrap_intersection_result(other, result)\n","\n","    def _intersection(self, other: Index, sort=False):\n","        \"\"\"\n","        intersection specialized to the case with matching dtypes.\n","        \"\"\"\n","        if (\n","            self.is_monotonic_increasing\n","            and other.is_monotonic_increasing\n","            and self._can_use_libjoin\n","        ):\n","            try:\n","                result = self._inner_indexer(other)[0]\n","            except TypeError:\n","                # non-comparable; should only be for object dtype\n","                pass\n","            else:\n","                # TODO: algos.unique1d should preserve DTA/TDA\n","                res = algos.unique1d(result)\n","                return ensure_wrapped_if_datetimelike(res)\n","\n","        res_values = self._intersection_via_get_indexer(other, sort=sort)\n","        res_values = _maybe_try_sort(res_values, sort)\n","        return res_values\n","\n","    def _wrap_intersection_result(self, other, result):\n","        # We will override for MultiIndex to handle empty results\n","        return self._wrap_setop_result(other, result)\n","\n","    @final\n","    def _intersection_via_get_indexer(self, other: Index, sort) -> ArrayLike:\n","        \"\"\"\n","        Find the intersection of two Indexes using get_indexer.\n","\n","        Returns\n","        -------\n","        np.ndarray or ExtensionArray\n","            The returned array will be unique.\n","        \"\"\"\n","        left_unique = self.unique()\n","        right_unique = other.unique()\n","\n","        # even though we are unique, we need get_indexer_for for IntervalIndex\n","        indexer = left_unique.get_indexer_for(right_unique)\n","\n","        mask = indexer != -1\n","\n","        taker = indexer.take(mask.nonzero()[0])\n","        if sort is False:\n","            # sort bc we want the elements in the same order they are in self\n","            # unnecessary in the case with sort=None bc we will sort later\n","            taker = np.sort(taker)\n","\n","        result = left_unique.take(taker)._values\n","        return result\n","\n","    @final\n","    def difference(self, other, sort=None):\n","        \"\"\"\n","        Return a new Index with elements of index not in `other`.\n","\n","        This is the set difference of two Index objects.\n","\n","        Parameters\n","        ----------\n","        other : Index or array-like\n","        sort : False or None, default None\n","            Whether to sort the resulting index. By default, the\n","            values are attempted to be sorted, but any TypeError from\n","            incomparable elements is caught by pandas.\n","\n","            * None : Attempt to sort the result, but catch any TypeErrors\n","              from comparing incomparable elements.\n","            * False : Do not sort the result.\n","\n","        Returns\n","        -------\n","        difference : Index\n","\n","        Examples\n","        --------\n","        >>> idx1 = pd.Index([2, 1, 3, 4])\n","        >>> idx2 = pd.Index([3, 4, 5, 6])\n","        >>> idx1.difference(idx2)\n","        Int64Index([1, 2], dtype='int64')\n","        >>> idx1.difference(idx2, sort=False)\n","        Int64Index([2, 1], dtype='int64')\n","        \"\"\"\n","        self._validate_sort_keyword(sort)\n","        self._assert_can_do_setop(other)\n","        other, result_name = self._convert_can_do_setop(other)\n","\n","        # Note: we do NOT call _deprecate_dti_setop here, as there\n","        #  is no requirement that .difference be commutative, so it does\n","        #  not cast to object.\n","\n","        if self.equals(other):\n","            # Note: we do not (yet) sort even if sort=None GH#24959\n","            return self[:0].rename(result_name)\n","\n","        if len(other) == 0:\n","            # Note: we do not (yet) sort even if sort=None GH#24959\n","            return self.rename(result_name)\n","\n","        if not self._should_compare(other):\n","            # Nothing matches -> difference is everything\n","            return self.rename(result_name)\n","\n","        result = self._difference(other, sort=sort)\n","        return self._wrap_difference_result(other, result)\n","\n","    def _difference(self, other, sort):\n","        # overridden by RangeIndex\n","\n","        this = self.unique()\n","\n","        indexer = this.get_indexer_for(other)\n","        indexer = indexer.take((indexer != -1).nonzero()[0])\n","\n","        label_diff = np.setdiff1d(np.arange(this.size), indexer, assume_unique=True)\n","        the_diff = this._values.take(label_diff)\n","        the_diff = _maybe_try_sort(the_diff, sort)\n","\n","        return the_diff\n","\n","    def _wrap_difference_result(self, other, result):\n","        # We will override for MultiIndex to handle empty results\n","        return self._wrap_setop_result(other, result)\n","\n","    def symmetric_difference(self, other, result_name=None, sort=None):\n","        \"\"\"\n","        Compute the symmetric difference of two Index objects.\n","\n","        Parameters\n","        ----------\n","        other : Index or array-like\n","        result_name : str\n","        sort : False or None, default None\n","            Whether to sort the resulting index. By default, the\n","            values are attempted to be sorted, but any TypeError from\n","            incomparable elements is caught by pandas.\n","\n","            * None : Attempt to sort the result, but catch any TypeErrors\n","              from comparing incomparable elements.\n","            * False : Do not sort the result.\n","\n","        Returns\n","        -------\n","        symmetric_difference : Index\n","\n","        Notes\n","        -----\n","        ``symmetric_difference`` contains elements that appear in either\n","        ``idx1`` or ``idx2`` but not both. Equivalent to the Index created by\n","        ``idx1.difference(idx2) | idx2.difference(idx1)`` with duplicates\n","        dropped.\n","\n","        Examples\n","        --------\n","        >>> idx1 = pd.Index([1, 2, 3, 4])\n","        >>> idx2 = pd.Index([2, 3, 4, 5])\n","        >>> idx1.symmetric_difference(idx2)\n","        Int64Index([1, 5], dtype='int64')\n","        \"\"\"\n","        self._validate_sort_keyword(sort)\n","        self._assert_can_do_setop(other)\n","        other, result_name_update = self._convert_can_do_setop(other)\n","        if result_name is None:\n","            result_name = result_name_update\n","\n","        if not is_dtype_equal(self.dtype, other.dtype):\n","            self._deprecate_dti_setop(other, \"symmetric_difference\")\n","\n","        if not self._should_compare(other):\n","            return self.union(other, sort=sort).rename(result_name)\n","\n","        elif not is_dtype_equal(self.dtype, other.dtype):\n","            dtype = self._find_common_type_compat(other)\n","            this = self.astype(dtype, copy=False)\n","            that = other.astype(dtype, copy=False)\n","            return this.symmetric_difference(that, sort=sort).rename(result_name)\n","\n","        this = self.unique()\n","        other = other.unique()\n","        indexer = this.get_indexer_for(other)\n","\n","        # {this} minus {other}\n","        common_indexer = indexer.take((indexer != -1).nonzero()[0])\n","        left_indexer = np.setdiff1d(\n","            np.arange(this.size), common_indexer, assume_unique=True\n","        )\n","        left_diff = this._values.take(left_indexer)\n","\n","        # {other} minus {this}\n","        right_indexer = (indexer == -1).nonzero()[0]\n","        right_diff = other._values.take(right_indexer)\n","\n","        res_values = concat_compat([left_diff, right_diff])\n","        res_values = _maybe_try_sort(res_values, sort)\n","\n","        # pass dtype so we retain object dtype\n","        result = Index(res_values, name=result_name, dtype=res_values.dtype)\n","\n","        if self._is_multi:\n","            self = cast(\"MultiIndex\", self)\n","            if len(result) == 0:\n","                # On equal symmetric_difference MultiIndexes the difference is empty.\n","                # Therefore, an empty MultiIndex is returned GH#13490\n","                return type(self)(\n","                    levels=[[] for _ in range(self.nlevels)],\n","                    codes=[[] for _ in range(self.nlevels)],\n","                    names=result.name,\n","                )\n","            return type(self).from_tuples(result, names=result.name)\n","\n","        return result\n","\n","    @final\n","    def _assert_can_do_setop(self, other) -> bool:\n","        if not is_list_like(other):\n","            raise TypeError(\"Input must be Index or array-like\")\n","        return True\n","\n","    def _convert_can_do_setop(self, other) -> tuple[Index, Hashable]:\n","        if not isinstance(other, Index):\n","            # TODO(2.0): no need to special-case here once _with_infer\n","            #  deprecation is enforced\n","            if hasattr(other, \"dtype\"):\n","                other = Index(other, name=self.name, dtype=other.dtype)\n","            else:\n","                # e.g. list\n","                other = Index(other, name=self.name)\n","            result_name = self.name\n","        else:\n","            result_name = get_op_result_name(self, other)\n","        return other, result_name\n","\n","    # --------------------------------------------------------------------\n","    # Indexing Methods\n","\n","    def get_loc(self, key, method=None, tolerance=None):\n","        \"\"\"\n","        Get integer location, slice or boolean mask for requested label.\n","\n","        Parameters\n","        ----------\n","        key : label\n","        method : {None, 'pad'/'ffill', 'backfill'/'bfill', 'nearest'}, optional\n","            * default: exact matches only.\n","            * pad / ffill: find the PREVIOUS index value if no exact match.\n","            * backfill / bfill: use NEXT index value if no exact match\n","            * nearest: use the NEAREST index value if no exact match. Tied\n","              distances are broken by preferring the larger index value.\n","\n","            .. deprecated:: 1.4\n","                Use index.get_indexer([item], method=...) instead.\n","\n","        tolerance : int or float, optional\n","            Maximum distance from index value for inexact matches. The value of\n","            the index at the matching location must satisfy the equation\n","            ``abs(index[loc] - key) <= tolerance``.\n","\n","        Returns\n","        -------\n","        loc : int if unique index, slice if monotonic index, else mask\n","\n","        Examples\n","        --------\n","        >>> unique_index = pd.Index(list('abc'))\n","        >>> unique_index.get_loc('b')\n","        1\n","\n","        >>> monotonic_index = pd.Index(list('abbc'))\n","        >>> monotonic_index.get_loc('b')\n","        slice(1, 3, None)\n","\n","        >>> non_monotonic_index = pd.Index(list('abcb'))\n","        >>> non_monotonic_index.get_loc('b')\n","        array([False,  True, False,  True])\n","        \"\"\"\n","        if method is None:\n","            if tolerance is not None:\n","                raise ValueError(\n","                    \"tolerance argument only valid if using pad, \"\n","                    \"backfill or nearest lookups\"\n","                )\n","            casted_key = self._maybe_cast_indexer(key)\n","            try:\n","                return self._engine.get_loc(casted_key)\n","            except KeyError as err:\n","                raise KeyError(key) from err\n","            except TypeError:\n","                # If we have a listlike key, _check_indexing_error will raise\n","                #  InvalidIndexError. Otherwise we fall through and re-raise\n","                #  the TypeError.\n","                self._check_indexing_error(key)\n","                raise\n","\n","        # GH#42269\n","        warnings.warn(\n","            f\"Passing method to {type(self).__name__}.get_loc is deprecated \"\n","            \"and will raise in a future version. Use \"\n","            \"index.get_indexer([item], method=...) instead.\",\n","            FutureWarning,\n","            stacklevel=find_stack_level(),\n","        )\n","\n","        if is_scalar(key) and isna(key) and not self.hasnans:\n","            raise KeyError(key)\n","\n","        if tolerance is not None:\n","            tolerance = self._convert_tolerance(tolerance, np.asarray(key))\n","\n","        indexer = self.get_indexer([key], method=method, tolerance=tolerance)\n","        if indexer.ndim > 1 or indexer.size > 1:\n","            raise TypeError(\"get_loc requires scalar valued input\")\n","        loc = indexer.item()\n","        if loc == -1:\n","            raise KeyError(key)\n","        return loc\n","\n","    _index_shared_docs[\n","        \"get_indexer\"\n","    ] = \"\"\"\n","        Compute indexer and mask for new index given the current index.\n","\n","        The indexer should be then used as an input to ndarray.take to align the\n","        current data to the new index.\n","\n","        Parameters\n","        ----------\n","        target : %(target_klass)s\n","        method : {None, 'pad'/'ffill', 'backfill'/'bfill', 'nearest'}, optional\n","            * default: exact matches only.\n","            * pad / ffill: find the PREVIOUS index value if no exact match.\n","            * backfill / bfill: use NEXT index value if no exact match\n","            * nearest: use the NEAREST index value if no exact match. Tied\n","              distances are broken by preferring the larger index value.\n","        limit : int, optional\n","            Maximum number of consecutive labels in ``target`` to match for\n","            inexact matches.\n","        tolerance : optional\n","            Maximum distance between original and new labels for inexact\n","            matches. The values of the index at the matching locations must\n","            satisfy the equation ``abs(index[indexer] - target) <= tolerance``.\n","\n","            Tolerance may be a scalar value, which applies the same tolerance\n","            to all values, or list-like, which applies variable tolerance per\n","            element. List-like includes list, tuple, array, Series, and must be\n","            the same size as the index and its dtype must exactly match the\n","            index's type.\n","\n","        Returns\n","        -------\n","        indexer : np.ndarray[np.intp]\n","            Integers from 0 to n - 1 indicating that the index at these\n","            positions matches the corresponding target values. Missing values\n","            in the target are marked by -1.\n","        %(raises_section)s\n","        Notes\n","        -----\n","        Returns -1 for unmatched values, for further explanation see the\n","        example below.\n","\n","        Examples\n","        --------\n","        >>> index = pd.Index(['c', 'a', 'b'])\n","        >>> index.get_indexer(['a', 'b', 'x'])\n","        array([ 1,  2, -1])\n","\n","        Notice that the return value is an array of locations in ``index``\n","        and ``x`` is marked by -1, as it is not in ``index``.\n","        \"\"\"\n","\n","    @Appender(_index_shared_docs[\"get_indexer\"] % _index_doc_kwargs)\n","    @final\n","    def get_indexer(\n","        self,\n","        target,\n","        method: str_t | None = None,\n","        limit: int | None = None,\n","        tolerance=None,\n","    ) -> npt.NDArray[np.intp]:\n","        method = missing.clean_reindex_fill_method(method)\n","        orig_target = target\n","        target = self._maybe_cast_listlike_indexer(target)\n","\n","        self._check_indexing_method(method, limit, tolerance)\n","\n","        if not self._index_as_unique:\n","            raise InvalidIndexError(self._requires_unique_msg)\n","\n","        if len(target) == 0:\n","            return np.array([], dtype=np.intp)\n","\n","        if not self._should_compare(target) and not self._should_partial_index(target):\n","            # IntervalIndex get special treatment bc numeric scalars can be\n","            #  matched to Interval scalars\n","            return self._get_indexer_non_comparable(target, method=method, unique=True)\n","\n","        if is_categorical_dtype(self.dtype):\n","            # _maybe_cast_listlike_indexer ensures target has our dtype\n","            #  (could improve perf by doing _should_compare check earlier?)\n","            assert is_dtype_equal(self.dtype, target.dtype)\n","\n","            indexer = self._engine.get_indexer(target.codes)\n","            if self.hasnans and target.hasnans:\n","                # After _maybe_cast_listlike_indexer, target elements which do not\n","                # belong to some category are changed to NaNs\n","                # Mask to track actual NaN values compared to inserted NaN values\n","                # GH#45361\n","                target_nans = isna(orig_target)\n","                loc = self.get_loc(np.nan)\n","                mask = target.isna()\n","                indexer[target_nans] = loc\n","                indexer[mask & ~target_nans] = -1\n","            return indexer\n","\n","        if is_categorical_dtype(target.dtype):\n","            # potential fastpath\n","            # get an indexer for unique categories then propagate to codes via take_nd\n","            # get_indexer instead of _get_indexer needed for MultiIndex cases\n","            #  e.g. test_append_different_columns_types\n","            categories_indexer = self.get_indexer(target.categories)\n","\n","            indexer = algos.take_nd(categories_indexer, target.codes, fill_value=-1)\n","\n","            if (not self._is_multi and self.hasnans) and target.hasnans:\n","                # Exclude MultiIndex because hasnans raises NotImplementedError\n","                # we should only get here if we are unique, so loc is an integer\n","                # GH#41934\n","                loc = self.get_loc(np.nan)\n","                mask = target.isna()\n","                indexer[mask] = loc\n","\n","            return ensure_platform_int(indexer)\n","\n","        pself, ptarget = self._maybe_promote(target)\n","        if pself is not self or ptarget is not target:\n","            return pself.get_indexer(\n","                ptarget, method=method, limit=limit, tolerance=tolerance\n","            )\n","\n","        if is_dtype_equal(self.dtype, target.dtype) and self.equals(target):\n","            # Only call equals if we have same dtype to avoid inference/casting\n","            return np.arange(len(target), dtype=np.intp)\n","\n","        if not is_dtype_equal(self.dtype, target.dtype) and not is_interval_dtype(\n","            self.dtype\n","        ):\n","            # IntervalIndex gets special treatment for partial-indexing\n","            dtype = self._find_common_type_compat(target)\n","\n","            this = self.astype(dtype, copy=False)\n","            target = target.astype(dtype, copy=False)\n","            return this._get_indexer(\n","                target, method=method, limit=limit, tolerance=tolerance\n","            )\n","\n","        return self._get_indexer(target, method, limit, tolerance)\n","\n","    def _get_indexer(\n","        self,\n","        target: Index,\n","        method: str_t | None = None,\n","        limit: int | None = None,\n","        tolerance=None,\n","    ) -> npt.NDArray[np.intp]:\n","        if tolerance is not None:\n","            tolerance = self._convert_tolerance(tolerance, target)\n","\n","        if method in [\"pad\", \"backfill\"]:\n","            indexer = self._get_fill_indexer(target, method, limit, tolerance)\n","        elif method == \"nearest\":\n","            indexer = self._get_nearest_indexer(target, limit, tolerance)\n","        else:\n","            if target._is_multi and self._is_multi:\n","                engine = self._engine\n","                # error: Item \"IndexEngine\" of \"Union[IndexEngine, ExtensionEngine]\"\n","                # has no attribute \"_extract_level_codes\"\n","                tgt_values = engine._extract_level_codes(  # type: ignore[union-attr]\n","                    target\n","                )\n","            else:\n","                tgt_values = target._get_engine_target()\n","\n","            indexer = self._engine.get_indexer(tgt_values)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YEDcUsz35zGO","outputId":"4b1fb4e9-a2e0-4643-d573-cc0bd1419835","executionInfo":{"status":"ok","timestamp":1682430104530,"user_tz":-180,"elapsed":1090,"user":{"displayName":"","userId":""}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[451.        ],\n","       [225.5       ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [180.4       ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [225.5       ],\n","       [902.        ],\n","       [225.5       ],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [451.        ],\n","       [180.4       ],\n","       [180.4       ],\n","       [451.        ],\n","       [451.        ],\n","       [225.5       ],\n","       [225.5       ],\n","       [300.66666667],\n","       [300.66666667],\n","       [902.        ],\n","       [300.66666667],\n","       [300.66666667],\n","       [300.66666667],\n","       [225.5       ],\n","       [150.33333333],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [225.5       ],\n","       [451.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [150.33333333],\n","       [300.66666667],\n","       [300.66666667],\n","       [902.        ],\n","       [451.        ],\n","       [300.66666667],\n","       [225.5       ],\n","       [902.        ],\n","       [451.        ],\n","       [150.33333333],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [150.33333333],\n","       [300.66666667],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [225.5       ],\n","       [300.66666667],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [300.66666667],\n","       [451.        ],\n","       [902.        ],\n","       [225.5       ],\n","       [225.5       ],\n","       [902.        ],\n","       [180.4       ],\n","       [300.66666667],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [180.4       ],\n","       [180.4       ],\n","       [225.5       ],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [300.66666667],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [180.4       ],\n","       [300.66666667],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [451.        ],\n","       [300.66666667],\n","       [180.4       ],\n","       [300.66666667],\n","       [180.4       ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [300.66666667],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [225.5       ],\n","       [451.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [451.        ],\n","       [300.66666667],\n","       [300.66666667],\n","       [225.5       ],\n","       [300.66666667],\n","       [451.        ],\n","       [902.        ],\n","       [180.4       ],\n","       [300.66666667],\n","       [451.        ],\n","       [300.66666667],\n","       [225.5       ],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [300.66666667],\n","       [300.66666667],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [225.5       ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [180.4       ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [225.5       ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [180.4       ],\n","       [300.66666667],\n","       [451.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [451.        ],\n","       [180.4       ],\n","       [451.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [300.66666667],\n","       [225.5       ],\n","       [451.        ],\n","       [300.66666667],\n","       [451.        ],\n","       [902.        ],\n","       [225.5       ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [225.5       ],\n","       [902.        ],\n","       [300.66666667],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [225.5       ],\n","       [300.66666667],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [300.66666667],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [300.66666667],\n","       [225.5       ],\n","       [902.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [902.        ],\n","       [180.4       ],\n","       [300.66666667],\n","       [451.        ],\n","       [451.        ],\n","       [225.5       ],\n","       [451.        ],\n","       [451.        ],\n","       [300.66666667],\n","       [300.66666667],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [300.66666667],\n","       [451.        ],\n","       [225.5       ],\n","       [902.        ],\n","       [300.66666667],\n","       [180.4       ],\n","       [451.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [180.4       ],\n","       [150.33333333],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [451.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [300.66666667],\n","       [902.        ],\n","       [300.66666667],\n","       [225.5       ],\n","       [225.5       ],\n","       [300.66666667],\n","       [902.        ],\n","       [300.66666667],\n","       [150.33333333],\n","       [180.4       ],\n","       [225.5       ],\n","       [451.        ],\n","       [225.5       ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [225.5       ],\n","       [451.        ],\n","       [225.5       ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [180.4       ],\n","       [300.66666667],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [225.5       ],\n","       [300.66666667],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [225.5       ],\n","       [451.        ],\n","       [451.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [451.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [225.5       ],\n","       [902.        ],\n","       [300.66666667],\n","       [300.66666667],\n","       [300.66666667],\n","       [902.        ],\n","       [225.5       ],\n","       [180.4       ],\n","       [902.        ],\n","       [300.66666667],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [451.        ],\n","       [300.66666667],\n","       [451.        ],\n","       [451.        ],\n","       [180.4       ],\n","       [902.        ],\n","       [902.        ],\n","       [225.5       ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [180.4       ],\n","       [180.4       ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [225.5       ],\n","       [902.        ],\n","       [451.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [902.        ],\n","       [150.33333333],\n","       [300.66666667],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [150.33333333],\n","       [300.66666667],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [225.5       ],\n","       [451.        ],\n","       [300.66666667],\n","       [300.66666667],\n","       [902.        ],\n","       [225.5       ],\n","       [225.5       ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [225.5       ],\n","       [902.        ],\n","       [451.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [451.        ],\n","       [300.66666667],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [180.4       ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [225.5       ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [300.66666667],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [300.66666667],\n","       [451.        ],\n","       [150.33333333],\n","       [300.66666667],\n","       [150.33333333],\n","       [300.66666667],\n","       [300.66666667],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [225.5       ],\n","       [225.5       ],\n","       [300.66666667],\n","       [451.        ],\n","       [225.5       ],\n","       [300.66666667],\n","       [300.66666667],\n","       [300.66666667],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [225.5       ],\n","       [902.        ],\n","       [451.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [300.66666667],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [300.66666667],\n","       [300.66666667],\n","       [180.4       ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [225.5       ],\n","       [451.        ],\n","       [225.5       ],\n","       [300.66666667],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [300.66666667],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [225.5       ],\n","       [902.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [180.4       ],\n","       [225.5       ],\n","       [451.        ],\n","       [150.33333333],\n","       [225.5       ],\n","       [902.        ],\n","       [300.66666667],\n","       [300.66666667],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [225.5       ],\n","       [451.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [180.4       ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [180.4       ],\n","       [902.        ],\n","       [902.        ],\n","       [225.5       ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [451.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [451.        ],\n","       [300.66666667],\n","       [300.66666667],\n","       [451.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [225.5       ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [451.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [225.5       ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [300.66666667],\n","       [300.66666667],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [300.66666667],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [225.5       ],\n","       [902.        ],\n","       [225.5       ],\n","       [300.66666667],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [225.5       ],\n","       [300.66666667],\n","       [150.33333333],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [300.66666667],\n","       [225.5       ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [300.66666667],\n","       [451.        ],\n","       [902.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [300.66666667],\n","       [902.        ],\n","       [225.5       ],\n","       [451.        ],\n","       [180.4       ],\n","       [451.        ],\n","       [451.        ],\n","       [225.5       ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [225.5       ],\n","       [902.        ],\n","       [902.        ],\n","       [225.5       ],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [225.5       ],\n","       [300.66666667],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ],\n","       [300.66666667],\n","       [180.4       ],\n","       [902.        ],\n","       [902.        ],\n","       [180.4       ],\n","       [225.5       ],\n","       [451.        ],\n","       [451.        ],\n","       [451.        ],\n","       [902.        ],\n","       [902.        ],\n","       [902.        ]])"]},"metadata":{},"execution_count":101}],"source":["train_dataset.w"]},{"cell_type":"markdown","metadata":{"id":"E8UCFrrN5zGf"},"source":["Notice that some elements are 0.  The weights are being used to indicate missing data.  Not all assays were actually performed on every molecule.  Setting the weight for a sample or sample/task pair to 0 causes it to be ignored during fitting and evaluation.  It will have no effect on the loss function or other metrics.\n","\n","Most of the other weights are close to 1, but not exactly 1.  This is done to balance the overall weight of positive and negative samples on each task.  When training the model, we want each of the 12 tasks to contribute equally, and on each task we want to put equal weight on positive and negative samples.  Otherwise, the model might just learn that most of the training samples are non-toxic, and therefore become biased toward identifying other molecules as non-toxic.\n","\n","# Training a Model on Fingerprints\n","\n","Let's train a model.  In earlier tutorials we use `GraphConvModel`, which is a fairly complicated architecture that takes a complex set of inputs.  Because fingerprints are so simple, just a single fixed length array, we can use a much simpler type of model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e5K3rdGV5zGg"},"outputs":[],"source":["model = dc.models.MultitaskClassifier(n_tasks=1, n_features=1024, layer_sizes=[1000])"]},{"cell_type":"markdown","metadata":{"id":"_Zcd7jTd5zGr"},"source":["`MultitaskClassifier` is a simple stack of fully connected layers.  In this example we tell it to use a single hidden layer of width 1000.  We also tell it that each input will have 1024 features, and that it should produce predictions for 12 different tasks.\n","\n","Why not train a separate model for each task?  We could do that, but it turns out that training a single model for multiple tasks often works better.  We will see an example of that in a later tutorial.\n","\n","Let's train and evaluate the model."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"LJc90fs_5zGs","outputId":"77b8363c-c468-4d20-a927-bbeaea3f9f49","executionInfo":{"status":"error","timestamp":1682430215484,"user_tz":-180,"elapsed":10,"user":{"displayName":"","userId":""}}},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-105-7f9eadcf160d>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training set score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/deepchem/models/torch_models/torch_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, nb_epoch, max_checkpoints_to_keep, checkpoint_interval, deterministic, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0maverage\u001b[0m \u001b[0mloss\u001b[0m \u001b[0mover\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmost\u001b[0m \u001b[0mrecent\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \"\"\"\n\u001b[0;32m--> 335\u001b[0;31m         return self.fit_generator(\n\u001b[0m\u001b[1;32m    336\u001b[0m             self.default_generator(dataset,\n\u001b[1;32m    337\u001b[0m                                    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/deepchem/models/torch_models/torch_model.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, max_checkpoints_to_keep, checkpoint_interval, restore, variables, loss, callbacks, all_losses)\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;31m# Main training loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/deepchem/models/fcnet.py\u001b[0m in \u001b[0;36mdefault_generator\u001b[0;34m(self, dataset, epochs, mode, deterministic, pad_batches)\u001b[0m\n\u001b[1;32m    181\u001b[0m                                                pad_batches=pad_batches):\n\u001b[1;32m    182\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0my_b\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                     y_b = to_one_hot(y_b.flatten(), self.n_classes).reshape(\n\u001b[0m\u001b[1;32m    184\u001b[0m                         -1, self.n_tasks, self.n_classes)\n\u001b[1;32m    185\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/deepchem/metrics/metric.py\u001b[0m in \u001b[0;36mto_one_hot\u001b[0;34m(y, n_classes)\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y must be a vector of shape (N,) or (N, 1)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y has more than n_class unique elements.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m     \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0my_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: y has more than n_class unique elements."]}],"source":["import numpy as np\n","\n","model.fit(train_dataset, nb_epoch=10)\n","metric = dc.metrics.Metric(dc.metrics.roc_auc_score)\n","print('training set score:', model.evaluate(train_dataset, [metric], transformers))\n","print('test set score:', model.evaluate(test_dataset, [metric], transformers))"]},{"cell_type":"markdown","metadata":{"id":"aQa88cbj5zGw"},"source":["Not bad performance for such a simple model and featurization.  More sophisticated models do slightly better on this dataset, but not enormously better."]},{"cell_type":"markdown","metadata":{"id":"MhZxVoVs5zMa"},"source":["# Congratulations! Time to join the Community!\n","\n","Congratulations on completing this tutorial notebook! If you enjoyed working through the tutorial, and want to continue working with DeepChem, we encourage you to finish the rest of the tutorials in this series. You can also help the DeepChem community in the following ways:\n","\n","## Star DeepChem on [GitHub](https://github.com/deepchem/deepchem)\n","This helps build awareness of the DeepChem project and the tools for open source drug discovery that we're trying to build.\n","\n","## Join the DeepChem Gitter\n","The DeepChem [Gitter](https://gitter.im/deepchem/Lobby) hosts a number of scientists, developers, and enthusiasts interested in deep learning for the life sciences. Join the conversation!"]},{"cell_type":"markdown","source":["## Citing This Tutorial\n","If you found this tutorial useful please consider citing it using the provided BibTeX. "],"metadata":{"id":"pOBd6-YdQSvF"}},{"cell_type":"code","source":["@manual{Intro4, \n"," title={Molecular Fingerprints}, \n"," organization={DeepChem},\n"," author={Ramsundar, Bharath}, \n"," howpublished = {\\url{https://github.com/deepchem/deepchem/blob/master/examples/tutorials/Molecular_Fingerprints.ipynb}}, \n"," year={2021}, \n","} "],"metadata":{"id":"KZUk_9yIYw0c","executionInfo":{"status":"error","timestamp":1682428554105,"user_tz":-180,"elapsed":12,"user":{"displayName":"","userId":""}},"outputId":"6e457469-2897-4077-e678-cf0dbc1a5d3f","colab":{"base_uri":"https://localhost:8080/","height":134}},"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-85-33832fe3f1d5>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    @manual{Intro4,\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"13z4ThGcuY7pYWJPAogzLS1Ra0F31RpVf","timestamp":1682432427918},{"file_id":"https://github.com/deepchem/deepchem/blob/master/examples/tutorials/Molecular_Fingerprints.ipynb","timestamp":1682432487706}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}